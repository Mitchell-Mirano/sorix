{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSELoss\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Mitchell-Mirano/sorix/blob/qa/docs/learn/loss/01-MSELoss.ipynb)\n",
    "[![Open in GitHub](https://img.shields.io/badge/Open%20in-GitHub-black?logo=github)](https://github.com/Mitchell-Mirano/sorix/blob/qa/docs/learn/loss/01-MSELoss.ipynb)\n",
    "[![Open in Docs](https://img.shields.io/badge/Open%20in-Docs-blue?logo=readthedocs)](https://mitchell-mirano.github.io/sorix/latest/learn/loss/01-MSELoss)\n",
    "\n",
    "The **Mean Squared Error** (MSE) loss measures the average of the squares of the errors. It is the most common loss function for **Regression** tasks.\n",
    "\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "Where:\n",
    "- $n$ is the batch size.\n",
    "- $y_i$ is the target value.\n",
    "- $\\hat{y}_i$ is the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next line and run this cell to install sorix\n",
    "#!pip install 'sorix @ git+https://github.com/Mitchell-Mirano/sorix.git@qa/docs_learn/docs_learn/docs_learn/docs_learn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T06:08:07.520941Z",
     "iopub.status.busy": "2026-03-01T06:08:07.520605Z",
     "iopub.status.idle": "2026-03-01T06:08:07.736500Z",
     "shell.execute_reply": "2026-03-01T06:08:07.735950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [2.5 0.  2.1]\n",
      "Targets:     [3. 0. 2.]\n",
      "MSE Loss:    0.0867\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sorix import tensor\n",
    "from sorix.nn import MSELoss\n",
    "\n",
    "# Create data\n",
    "y_pred = tensor([2.5, 0.0, 2.1], requires_grad=True)\n",
    "y_true = tensor([3.0, 0.0, 2.0])\n",
    "\n",
    "criterion = MSELoss()\n",
    "loss = criterion(y_pred, y_true)\n",
    "\n",
    "print(f\"Predictions: {y_pred.numpy()}\")\n",
    "print(f\"Targets:     {y_true.numpy()}\")\n",
    "print(f\"MSE Loss:    {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification with Autograd\n",
    "\n",
    "MSELoss in Sorix is fully differentiable. If we compute the backward pass, we can see the gradients w.r.t the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T06:08:07.755894Z",
     "iopub.status.busy": "2026-03-01T06:08:07.755728Z",
     "iopub.status.idle": "2026-03-01T06:08:07.758546Z",
     "shell.execute_reply": "2026-03-01T06:08:07.758041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients w.r.t y_pred: [-0.33333334  0.          0.0666666 ]\n",
      "Manual Gradients:     [-0.33333334  0.          0.0666666 ]\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(f\"Gradients w.r.t y_pred: {y_pred.grad}\")\n",
    "\n",
    "# Manual verification: d/dy_pred (1/n * (y_pred - y_true)^2) = 2/n * (y_pred - y_true)\n",
    "n = y_pred.data.size\n",
    "manual_grad = 2/n * (y_pred.data - y_true.data)\n",
    "print(f\"Manual Gradients:     {manual_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Example\n",
    "\n",
    "Let's see how `MSELoss` guides a single value to match a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T06:08:07.760158Z",
     "iopub.status.busy": "2026-03-01T06:08:07.760040Z",
     "iopub.status.idle": "2026-03-01T06:08:07.765124Z",
     "shell.execute_reply": "2026-03-01T06:08:07.764563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weight: 10.00\n",
      "Step  0 | Weight: 16.4000 | Loss: 1024.0000\n",
      "Step  5 | Weight: 33.6114 | Loss: 109.9512\n",
      "Step 10 | Weight: 39.2512 | Loss: 11.8059\n",
      "Step 15 | Weight: 41.0993 | Loss: 1.2676\n",
      "Step 20 | Weight: 41.7049 | Loss: 0.1361\n",
      "Final weight: 41.70\n"
     ]
    }
   ],
   "source": [
    "from sorix.optim import SGD\n",
    "\n",
    "weight = tensor([10.0], requires_grad=True)\n",
    "target = tensor([42.0])\n",
    "optimizer = SGD([weight], lr=0.1)\n",
    "\n",
    "print(f\"Initial weight: {weight.item():.2f}\")\n",
    "\n",
    "for i in range(21):\n",
    "    loss = criterion(weight, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if i % 5 == 0:\n",
    "        print(f\"Step {i:2d} | Weight: {weight.item():.4f} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(f\"Final weight: {weight.item():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}